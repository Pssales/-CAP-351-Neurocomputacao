{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# \tnum_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    " \n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "# one-hot encode the training and testing labels\n",
    "trainY = np_utils.to_categorical(trainY, 10)\n",
    "testY = np_utils.to_categorical(testY, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From C:\\Users\\Camila\\Anaconda3\\envs\\pdi\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[INFO] training model...\n",
      "WARNING:tensorflow:From C:\\Users\\Camila\\Anaconda3\\envs\\pdi\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 209s 3ms/step - loss: 0.5507 - accuracy: 0.8166 - val_loss: 0.3755 - val_accuracy: 0.8635\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 206s 3ms/step - loss: 0.3415 - accuracy: 0.8784 - val_loss: 0.2709 - val_accuracy: 0.9028\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 205s 3ms/step - loss: 0.2973 - accuracy: 0.8927 - val_loss: 0.2506 - val_accuracy: 0.9085\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 205s 3ms/step - loss: 0.2699 - accuracy: 0.9021 - val_loss: 0.2434 - val_accuracy: 0.9104\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 206s 3ms/step - loss: 0.2552 - accuracy: 0.9078 - val_loss: 0.2322 - val_accuracy: 0.9147\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 205s 3ms/step - loss: 0.2399 - accuracy: 0.9130 - val_loss: 0.2265 - val_accuracy: 0.9150\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.2339 - accuracy: 0.9166 - val_loss: 0.2148 - val_accuracy: 0.9203\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2242 - accuracy: 0.9186 - val_loss: 0.2260 - val_accuracy: 0.9166\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2201 - accuracy: 0.9198 - val_loss: 0.2159 - val_accuracy: 0.9197\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.2137 - accuracy: 0.9219 - val_loss: 0.2076 - val_accuracy: 0.9246\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.2094 - accuracy: 0.9242 - val_loss: 0.2094 - val_accuracy: 0.9239\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 204s 3ms/step - loss: 0.2061 - accuracy: 0.9249 - val_loss: 0.1996 - val_accuracy: 0.9263\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 204s 3ms/step - loss: 0.2047 - accuracy: 0.9248 - val_loss: 0.1991 - val_accuracy: 0.9258\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 205s 3ms/step - loss: 0.1982 - accuracy: 0.9277 - val_loss: 0.1959 - val_accuracy: 0.9271\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 215s 4ms/step - loss: 0.1956 - accuracy: 0.9295 - val_loss: 0.1950 - val_accuracy: 0.9277\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 211s 4ms/step - loss: 0.1920 - accuracy: 0.9302 - val_loss: 0.1964 - val_accuracy: 0.9269\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 211s 4ms/step - loss: 0.1887 - accuracy: 0.9308 - val_loss: 0.1950 - val_accuracy: 0.9273\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 0.1882 - accuracy: 0.9312 - val_loss: 0.1959 - val_accuracy: 0.9281\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 220s 4ms/step - loss: 0.1864 - accuracy: 0.9319 - val_loss: 0.1944 - val_accuracy: 0.9306\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.1824 - accuracy: 0.9328 - val_loss: 0.1874 - val_accuracy: 0.9312\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 221s 4ms/step - loss: 0.1818 - accuracy: 0.9341 - val_loss: 0.1870 - val_accuracy: 0.9325\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 226s 4ms/step - loss: 0.1814 - accuracy: 0.9347 - val_loss: 0.1876 - val_accuracy: 0.9320\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 226s 4ms/step - loss: 0.1764 - accuracy: 0.9363 - val_loss: 0.1871 - val_accuracy: 0.9325\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.1765 - accuracy: 0.9359 - val_loss: 0.1929 - val_accuracy: 0.9294\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.1726 - accuracy: 0.9383 - val_loss: 0.1871 - val_accuracy: 0.9315\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.89      0.88      0.88      1000\n",
      "     trouser       1.00      0.98      0.99      1000\n",
      "    pullover       0.90      0.91      0.90      1000\n",
      "       dress       0.94      0.93      0.93      1000\n",
      "        coat       0.88      0.90      0.89      1000\n",
      "      sandal       0.99      0.99      0.99      1000\n",
      "       shirt       0.79      0.79      0.79      1000\n",
      "     sneaker       0.96      0.98      0.97      1000\n",
      "         bag       0.99      0.99      0.99      1000\n",
      "  ankle boot       0.99      0.96      0.97      1000\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(trainX, trainY,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tbatch_size=BS, epochs=NUM_EPOCHS)\n",
    "\n",
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "\ttarget_names=labelNames))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-29c65e8e18b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loss and Accuracy on Dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our list of output images\n",
    "images = []\n",
    "\n",
    "# randomly select a few testing fashion items\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "\t# classify the clothing\n",
    "\tprobs = model.predict(testX[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\tlabel = labelNames[prediction[0]]\n",
    " \n",
    "\t# extract the image from the testData if using \"channels_first\"\n",
    "\t# ordering\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
    " \n",
    "\t# otherwise we are using \"channels_last\" ordering\n",
    "\telse:\n",
    "\t\timage = (testX[i] * 255).astype(\"uint8\")\n",
    "\n",
    "\t# initialize the text label color as green (correct)\n",
    "\tcolor = (0, 255, 0)\n",
    "\n",
    "\t# otherwise, the class label prediction is incorrect\n",
    "\tif prediction[0] != np.argmax(testY[i]):\n",
    "\t\tcolor = (0, 0, 255)\n",
    " \n",
    "\t# merge the channels into one image and resize the image from\n",
    "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
    "\t# predicted label on the image\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "\t\tcolor, 2)\n",
    "\n",
    "\t# add the image to our list of output images\n",
    "\timages.append(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the montage for the images\n",
    "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
    "\n",
    "# show the output montage\n",
    "cv2.imshow(\"Fashion MNIST\", montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pdi)",
   "language": "python",
   "name": "pdi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
